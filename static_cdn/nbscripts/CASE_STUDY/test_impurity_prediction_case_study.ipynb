{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains tests for the multiplication functions within the multiply module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Test-variables\" data-toc-modified-id=\"Test-variables-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Test variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#A-valid-training-dataframe\" data-toc-modified-id=\"A-valid-training-dataframe-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>A valid training dataframe</a></span></li><li><span><a href=\"#The-correct-output-column-and-columns-to-be-discarded-from-the-training-dataset\" data-toc-modified-id=\"The-correct-output-column-and-columns-to-be-discarded-from-the-training-dataset-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>The correct output column and columns to be discarded from the training dataset</a></span></li><li><span><a href=\"#The-valid-manual-ML-model-creation\" data-toc-modified-id=\"The-valid-manual-ML-model-creation-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>The valid manual ML model creation</a></span></li><li><span><a href=\"#A-valid-dataframe-to-be-used-for-prediction\" data-toc-modified-id=\"A-valid-dataframe-to-be-used-for-prediction-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>A valid dataframe to be used for prediction</a></span></li><li><span><a href=\"#The-valid-manual-ML-prediction\" data-toc-modified-id=\"The-valid-manual-ML-prediction-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>The valid manual ML prediction</a></span></li><li><span><a href=\"#valid-csvs-for-single-step-input\" data-toc-modified-id=\"valid-csvs-for-single-step-input-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>valid csvs for single step input</a></span></li><li><span><a href=\"#valid-output-graph\" data-toc-modified-id=\"valid-output-graph-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>valid output graph</a></span></li></ul></li><li><span><a href=\"#Test-Functions\" data-toc-modified-id=\"Test-Functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Test Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#FUNCTION-linear_reg_model_creation-FOR-invalid-parameters\" data-toc-modified-id=\"FUNCTION-linear_reg_model_creation-FOR-invalid-parameters-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>FUNCTION linear_reg_model_creation FOR invalid parameters</a></span></li><li><span><a href=\"#FUNCTION-prediction_using_model-FOR-invalid-parameters\" data-toc-modified-id=\"FUNCTION-prediction_using_model-FOR-invalid-parameters-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>FUNCTION prediction_using_model FOR invalid parameters</a></span></li><li><span><a href=\"#FUNCTION-single_step_create_predict-FOR-invalid-parameters\" data-toc-modified-id=\"FUNCTION-single_step_create_predict-FOR-invalid-parameters-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>FUNCTION single_step_create_predict FOR invalid parameters</a></span></li><li><span><a href=\"#FUNCTION-linear_reg_model_creation-FOR-valid-parameters\" data-toc-modified-id=\"FUNCTION-linear_reg_model_creation-FOR-valid-parameters-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>FUNCTION linear_reg_model_creation FOR valid parameters</a></span></li><li><span><a href=\"#FUNCTION-prediction_using_model-FOR-valid-parameters\" data-toc-modified-id=\"FUNCTION-prediction_using_model-FOR-valid-parameters-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>FUNCTION prediction_using_model FOR valid parameters</a></span></li><li><span><a href=\"#FUNCTION-single_step_create_predict-FOR-valid-parameters\" data-toc-modified-id=\"FUNCTION-single_step_create_predict-FOR-valid-parameters-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>FUNCTION single_step_create_predict FOR valid parameters</a></span></li><li><span><a href=\"#FUNCTION-linear_reg_model_creation-FOR-misspelt-columns\" data-toc-modified-id=\"FUNCTION-linear_reg_model_creation-FOR-misspelt-columns-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>FUNCTION linear_reg_model_creation FOR misspelt columns</a></span></li><li><span><a href=\"#FUNCTION-prediction_using_model-FOR-misspelt-columns\" data-toc-modified-id=\"FUNCTION-prediction_using_model-FOR-misspelt-columns-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>FUNCTION prediction_using_model FOR misspelt columns</a></span></li><li><span><a href=\"#FUNCTION-linear_reg_model_creation-FOR-list-variations\" data-toc-modified-id=\"FUNCTION-linear_reg_model_creation-FOR-list-variations-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>FUNCTION linear_reg_model_creation FOR list variations</a></span></li><li><span><a href=\"#FUNCTION-prediction_using_model-FOR-list-variations\" data-toc-modified-id=\"FUNCTION-prediction_using_model-FOR-list-variations-3.10\"><span class=\"toc-item-num\">3.10&nbsp;&nbsp;</span>FUNCTION prediction_using_model FOR list variations</a></span></li><li><span><a href=\"#FUNCTION-linear_reg_model_creation-FOR-compare-in_out_def\" data-toc-modified-id=\"FUNCTION-linear_reg_model_creation-FOR-compare-in_out_def-3.11\"><span class=\"toc-item-num\">3.11&nbsp;&nbsp;</span>FUNCTION linear_reg_model_creation FOR compare in_out_def</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importnb import Notebook\n",
    "import pytest\n",
    "import inspect\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "with __import__('importnb').Notebook():\n",
    "    from impurity_prediction_case_study import prediction_using_model as predict_func\n",
    "    from impurity_prediction_case_study import linear_reg_model_creation as model_creation_func\n",
    "    from impurity_prediction_case_study import single_step_create_predict as single_step\n",
    "    from impurity_prediction_case_study import in_out_def\n",
    "    from df_to_fig import df_to_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A valid training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the column names that will be in the fake training DataFrame\n",
    "cols = [\"%_Iron_Feed\", \"%_Silica_Feed\", \"Starch_Flow\", \"Amina_Flow\",\n",
    "        \"Ore_Pulp_Flow\", \"Ore_Pulp_pH\", \"Ore_Pulp_Density\", \"Flotation_Column_01_Air_Flow\",\n",
    "        \"Flotation_Column_02_Air_Flow\", \"Flotation_Column_03_Air_Flow\", \"Flotation_Column_04_Air_Flow\",\n",
    "        \"Flotation_Column_05_Air_Flow\", \"Flotation_Column_06_Air_Flow\", \"Flotation_Column_07_Air_Flow\",\n",
    "        \"Flotation_Column_01_Level\", \"Flotation_Column_02_Level\", \"Flotation_Column_03_Level\", \"Flotation_Column_04_Level\",\n",
    "        \"Flotation_Column_05_Level\", \"Flotation_Column_06_Level\", \"Flotation_Column_07_Level\", \"%_Iron_Concentrate\",\n",
    "        \"%_Silica_Concentrate\"]\n",
    "# create a list of lists which contains the data to populate the DataFrame\n",
    "dat = [\n",
    "    [55.2, 16.98, 3150.39, 558472, 397852, 100755, 1.74, 249.17, 249829, 251147, 295096, 306.4,\n",
    "        250928, 246533, 461.45, 421.41, 467.79, 458.59, 453.84, 448.05, 451.34, 66.91, 1.31],\n",
    "    [55.2, 16.98, 2877.93, 523071, 403857, 101448, 164431, 249.5, 252246, 249.17, 295096, 306.4,\n",
    "        250159, 249.17, 460199, 450.29, 440.27, 460545, 450.54, 439365, 433405, 67.06, 1.11],\n",
    "    [55.2, 16.98, 3545.12, 602417, 395801, 100826, 173916, 248.73, 250983, 250818, 295096, 306.4,\n",
    "        249884, 249.92, 452692, 511325, 458213, 443845, 429885, 439.09, 424992, 66.97, 1.27],\n",
    "    [56.41, 14.53, 3605.99, 500896, 398934, 949171, 167684, 250022, 253921, 248644, 300419,\n",
    "        302691, 308086, 298881, 407758, 407365, 452814, 342004, 348725, 325872, 359233, 63.6, 4.06],\n",
    "    [53.63, 15.74, 3415.17, 537159, 399023, 100181, 168234, 301586, 301064, 302978, 297673, 300927,\n",
    "        309124, 293425, 406626, 8.18285E+11, 391703, 394874, 386249, 391795, 419623, 64.76, 2.01],\n",
    "    [57.46, 10.8, 3914.79, 566473, 400563, 101896, 174859, 250314, 300164, 299617, 301707, 299927,\n",
    "        295017, 306587, 501298, 7.74487E+12, 402394, 344.09, 328136, 337138, 302587, 64.9, 3.82],\n",
    "    [55.1, 15.95, 2171.05, 554702, 383618, 992454, 172271, 298578, 307983, 298806, 3.04989E+12, 2.93961E+12,\n",
    "        338964, 349532, 397077, 508339, 415503, 343612, 336094, 360217, 1.86778E+11, 62.68, 4.52],\n",
    "    [53.24, 19.97, 4216.94, 583304, 384266, 938014, 173908, 301313, 299068, 299.47, 300.57, 300233,\n",
    "        306506, 290461, 410361, 382.91, 8.84373E+12, 390635, 353515, 435931, 365177, 63.13, 4.14],\n",
    "    [47.24, 26.08, 5138.54, 510345, 408616, 917929, 171831, 299.74, 296.48, 296794, 301396,\n",
    "        296869, 293567, 305408, 609142, 490.24, 561679, 398907, 459588, 482576, 448534, 65.82, 2.39],\n",
    "    [49.75, 23.2, 2735.63, 462036, 383337, 961952, 165407, 302344, 298306, 299703, 298857, 299941,\n",
    "        343017, 294.93, 387791, 554852, 862431, 442184, 490475, 417519, 360781, 64.27, 1.71],\n",
    "    [54.52, 20.56, 2219.74, 509352, 398201, 937682, 169416, 298828, 297867, 299359, 300074,\n",
    "        298789, 299.34, 301015, 502.58, 497076, 500655, 402296, 405243, 394949, 377344, 65.28, 3.02],\n",
    "    [64.03, 6.26, 1644.63, 414533, 395464, 958047, 154283, 300656, 307233, 300754, 299889,\n",
    "        299497, 296627, 299707, 442753, 455668, 458514, 348313, 363595, 367979, 378327, 65.38, 1.2],\n",
    "    [64.03, 6.26, 3643.58, 414619, 402.2, 101458, 172885, 299504, 299367, 301867, 300263, 301411,\n",
    "        304855, 301864, 594756, 592947, 603106, 493593, 442699, 499667, 459587, 66.84, 1.72],\n",
    "    [49.85, 21.61, 3162.58, 559103, 398651, 996541, 169636, 299595, 301617, 299611, 300917,\n",
    "        301469, 305248, 301166, 408824, 398272, 395197, 425095, 454627, 447625, 425846, 64.84, 2.81],\n",
    "    [64.03, 6.26, 4040.34, 450.65, 403328, 101854, 16887, 300733, 301.9, 300299, 299927, 298897,\n",
    "        298245, 299704, 402904, 386472, 394077, 430864, 419664, 388.5, 380565, 66.2, 1.19],\n",
    "    [56.42, 12.99, 1632.81, 401001, 399316, 965007, 174914, 250598, 252466, 251697, 295096,\n",
    "        306.4, 250378, 250049, 250169, 482865, 529835, 504.1, 597.32, 631.75, 576.59, 66.17, 1.38],\n",
    "    [56.02, 14.42, 2197.19, 532.02, 399764, 928175, 173193, 249784, 249493, 249249, 295096,\n",
    "        306.4, 249609, 250952, 787.39, 813616, 796815, 376187, 411236, 646687, 404522, 65.9, 1.83],\n",
    "    [56.57, 13.47, 2100.91, 456126, 398788, 947472, 174726, 249095, 251849, 250542, 295096,\n",
    "        306.4, 252327, 248988, 691162, 487.29, 703.85, 467.35, 506261, 461801, 520078, 65.95, 1.47],\n",
    "    [55.78, 12.85, 3540.13, 500.22, 400004, 103208, 163129, 300317, 291417, 298487, 299124,\n",
    "        296729, 305851, 292015, 404544, 414101, 388855, 362905, 389953, 396767, 347427, 65.87, 1.27]\n",
    "]\n",
    "# create the DataFrame\n",
    "example_dataframe = pd.DataFrame(data=dat, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The correct output column and columns to be discarded from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the output (what we want to predict) column\n",
    "example_out_col = \"%_Silica_Concentrate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifiy which columns will be dropped (not required for prediction) from the DataFrame\n",
    "example_not_required = \"%_Iron_Concentrate,Ore_Pulp_pH,Flotation_Column_01_Air_Flow,Flotation_Column_02_Air_Flow,Flotation_Column_03_Air_Flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The valid manual ML model creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the column text list ot a python list\n",
    "columns_not_required = example_not_required.split(\",\")\n",
    "# duplicate the DataFrame to prevent any changes impacting the original\n",
    "df = example_dataframe.copy().drop(columns_not_required, axis=1)\n",
    "# perform the model creation (see main notebook for detail)\n",
    "Y = df[example_out_col]\n",
    "X = df.drop([\"%_Silica_Concentrate\"], axis=1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(min_max_scaler.fit_transform(X), columns=X.columns)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.3, random_state=42)\n",
    "reg = LinearRegression()\n",
    "_ = reg.fit(X_train, Y_train)\n",
    "predictions = reg.predict(X_test)\n",
    "error = mean_squared_error(Y_test, predictions)\n",
    "# create the dictionaries which should be returned by the ml model creation functions when using the example data\n",
    "example_true_model_output = {\"reg\": reg, \"scaler_used\": min_max_scaler,\n",
    "                             \"mean_squared_error\": error, \"regression_cols\": [*X_test.columns]}\n",
    "example_false_model_output = {\"reg\": None, \"scaler_used\": None,\n",
    "                              \"mean_squared_error\": None, \"regression_cols\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A valid dataframe to be used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the columns which will be found in the fake DataFrame to be used for predictions\n",
    "df_predict_cols = \"%_Iron_Feed,%_Silica_Feed,Starch_Flow,Amina_Flow,Ore_Pulp_Flow,Ore_Pulp_Density,Flotation_Column_04_Air_Flow,Flotation_Column_05_Air_Flow,Flotation_Column_06_Air_Flow,Flotation_Column_07_Air_Flow,Flotation_Column_01_Level,Flotation_Column_02_Level,Flotation_Column_03_Level,Flotation_Column_04_Level,Flotation_Column_05_Level,Flotation_Column_06_Level,Flotation_Column_07_Level\".split(\n",
    "    \",\")\n",
    "# create list of lists which contains the data to populate the fake prediction DataFrame\n",
    "to_predict_dat = [[55.2, 16.98, 3316.41, 549.927, 394.043, 1.72028, 295.096, 306.4, 252.686, 247.632, 471.96, 504.1, 461.86, 473.83, 454.39, 423.96, 400.58],\n",
    "                  [55.2, 16.98, 3309.38, 555.786, 397.91, 1.71917, 295.096, 306.4, 253.345,\n",
    "                      249.214, 456.345, 270.97, 455.38, 475.468, 466.288, 451.518, 413.822],\n",
    "                  [55.2, 16.98, 3325.78, 552.002, 400.137, 1.7178, 295.096, 306.4, 254.18,\n",
    "                      251.455, 435.725, 324.439, 451.06, 491.092, 500.662, 484.338, 437.212],\n",
    "                  [55.2, 16.98, 3356.25, 552.002, 397.793, 1.71642, 295.096, 306.4, 251.543,\n",
    "                   250.664, 433.723, 377.908, 445.558, 479.216, 496.804, 497.666, 465.79],\n",
    "                  [55.2, 16.98, 3376.56, 554.688, 400.605, 1.71504, 295.096, 306.4, 248.423,\n",
    "                   249.478, 444.133, 500.028, 439.946, 429.92, 462.986, 501.138, 502.208],\n",
    "                  [55.2, 16.98, 3410.94, 557.338, 403.251, 1.71367, 295.096, 306.4, 247.506,\n",
    "                   250.143, 446.65, 504.426, 438.347, 410.211, 452.824, 509.81, 524.089],\n",
    "                  [55.2, 16.98, 3522.27, 550.293, 406.348, 1.71229, 295.096, 306.4, 251.038,\n",
    "                   249.5, 444.934, 513.164, 445.237, 422.773, 449.494, 488.398, 489.739],\n",
    "                  [55.2, 16.98, 3565.23, 552.673, 402.217, 1.71091, 295.096, 306.4, 253.037,\n",
    "                   248.269, 438.878, 520.359, 448.987, 436.663, 449.573, 448.106, 435.201],\n",
    "                  [55.2, 16.98, 3591.41, 555.542, 401.514, 1.70954, 295.096, 306.4, 251.884,\n",
    "                   248.796, 439.979, 505.007, 448.775, 449.572, 458.141, 430.405, 405.349],\n",
    "                  [55.2, 16.98, 3591.52, 572.296, 404.019, 1.70816, 295.096, 306.4, 252.191, 250.719, 449.063, 417.806, 446.129, 453.027, 473.011, 448.829, 400.411]]\n",
    "# Create the fake prediciton DataFrame\n",
    "example_predict_dataframe = pd.DataFrame(\n",
    "    data=to_predict_dat, columns=df_predict_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The valid manual ML prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a string list from a python list for the prediction column name list\n",
    "example_regression_columns = \"\"\n",
    "for i, x in enumerate(X_test.columns):\n",
    "    example_regression_columns += x\n",
    "    example_regression_columns = (example_regression_columns+\",\" if i !=\n",
    "                                  len([*X_test.columns])-1 else example_regression_columns)\n",
    "# perform the prediction using the test data and test model (previously created)\n",
    "X2 = example_predict_dataframe[[*X_test.columns]]\n",
    "X2_scaled = pd.DataFrame(min_max_scaler.transform(X2),\n",
    "                         columns=[*X_test.columns])\n",
    "predictions = reg.predict(X2_scaled)\n",
    "X2[\"Predicted_%_Silica_Concentrate\"] = pd.Series(predictions)\n",
    "# return the dictionary expected by correct calculations\n",
    "example_prediction = {\"df\": X2}\n",
    "#print(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid csvs for single step input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fake csv file from the fake training DataFrame\n",
    "# put in function as the fake csv once read will require the seek(0) to be applied again\n",
    "def example_training_csv():\n",
    "    example_csv = StringIO()\n",
    "    file_buff = example_dataframe.to_csv(example_csv, index=False)\n",
    "    example_csv.seek(0)\n",
    "    return example_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prediction csv by first applying the inverse of the conversions to be applied to the DataFrame\n",
    "\n",
    "example_predict_dataframe_single = example_predict_dataframe.copy()\n",
    "conversions = [(['Starch_Flow', 'Amina_Flow', 'Ore_Pulp_Flow'], 101.941), (['Ore_Pulp_Density'], 0.0000160185), (['Flotation_Column_01_Level', 'Flotation_Column_02_Level'\n",
    "                                                                                                                  ], 25.4)]\n",
    "# traverse this t and apply the conversions\n",
    "for conv_tuple in conversions:\n",
    "    for col in conv_tuple[0]:\n",
    "        example_predict_dataframe_single[col] = pd.to_numeric(\n",
    "            example_predict_dataframe_single[col], errors='coerce')\n",
    "        example_predict_dataframe_single[col] = example_predict_dataframe_single[col]/conv_tuple[1]\n",
    "\n",
    "\n",
    "def example_prediction_csv():\n",
    "    example_csv = StringIO()\n",
    "    file_buff = example_predict_dataframe_single.to_csv(\n",
    "        example_csv, index=False)\n",
    "    example_csv.seek(0)\n",
    "    return example_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid output graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure dictionary\n",
    "example_prediction_fig = df_to_hist(\n",
    "    df=example_prediction['df'].copy(), data='Predicted_%_Silica_Concentrate', group_by='None', bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION linear_reg_model_creation FOR invalid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass 1 invalid parameter to the function. Vary which parameter this is using parametrize.\n",
    "@pytest.mark.parametrize(\"a,b,c\", [\n",
    "    (1, example_out_col, example_not_required),\n",
    "    (example_dataframe, 1, example_not_required),\n",
    "    (example_dataframe, example_out_col, 1),\n",
    "    (None, None, None)])\n",
    "def test_create_model_invalid_params(a, b, c):\n",
    "    '''Testing the correct error dictionary is returned when no parameters are specified'''\n",
    "    assert model_creation_func(\n",
    "        df=a, output_column=b, columns_not_required=c) == example_false_model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION prediction_using_model FOR invalid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass 1 invalid parameter to the function. Vary which parameter this is using parametrize.\n",
    "@pytest.mark.parametrize(\"a,b,c,d\", [\n",
    "    (1, example_true_model_output[\"scaler_used\"],\n",
    "     example_predict_dataframe, example_regression_columns),\n",
    "    (example_true_model_output[\"reg\"], 1,\n",
    "     example_predict_dataframe, example_regression_columns),\n",
    "    (example_true_model_output[\"reg\"],\n",
    "     example_true_model_output[\"scaler_used\"], 1, example_regression_columns),\n",
    "    (example_true_model_output[\"reg\"],\n",
    "     example_true_model_output[\"scaler_used\"], example_predict_dataframe, 1),\n",
    "    (None, None, None, None)])\n",
    "def test_predict_invalid_params(a, b, c, d):\n",
    "    assert predict_func(model=a,\n",
    "                        scaler_used=b, df=c, regression_cols=d) == {\"df\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION single_step_create_predict FOR invalid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass 1 invalid parameter to the function. Vary which parameter this is using parametrize.\n",
    "@pytest.mark.parametrize(\"a,b,c,d\", [\n",
    "    (1, example_prediction_csv(), example_out_col, example_not_required),\n",
    "    (example_training_csv(), 1, example_out_col, example_not_required),\n",
    "    (example_training_csv(), example_prediction_csv(), 1, example_not_required),\n",
    "    (example_training_csv(), example_prediction_csv(), example_out_col, 1),\n",
    "    (None, None, None, None)])\n",
    "def test_single_step_create_predict_invalid_params(a, b, c, d):\n",
    "    '''Testing the correct error dictionary is returned when no parameters are specified'''\n",
    "    assert single_step(training_csv=a, predict_csv=b, output_column=c,\n",
    "                       columns_not_required=d) == {\"df\": None, \"fig\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION linear_reg_model_creation FOR valid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a supporting function for comparing the output dictionaries\n",
    "def compare_model_dicts(dict_a, dict_b):\n",
    "    model_check = not False in (dict_a[\"reg\"].coef_ == dict_b[\"reg\"].coef_)\n",
    "    scaler_check = not False in (\n",
    "        dict_a[\"scaler_used\"].scale_ == dict_b[\"scaler_used\"].scale_)\n",
    "    mse_check = dict_a[\"mean_squared_error\"] == dict_b[\"mean_squared_error\"]\n",
    "    cols_check = dict_a[\"regression_cols\"] == dict_b[\"regression_cols\"]\n",
    "    return model_check and scaler_check and mse_check and cols_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the function results to the test results\n",
    "def test_create_model_valid_params():\n",
    "    dict_a = model_creation_func(\n",
    "        df=example_dataframe, output_column=example_out_col, columns_not_required=example_not_required)\n",
    "    dict_b = example_true_model_output\n",
    "    # print(dict_a)\n",
    "    assert compare_model_dicts(dict_a, dict_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION prediction_using_model FOR valid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the function results to the test results\n",
    "def test_predict_valid_params():\n",
    "    dict_a = predict_func(model=example_true_model_output[\"reg\"],\n",
    "                          scaler_used=example_true_model_output[\"scaler_used\"], df=example_predict_dataframe,\n",
    "                          regression_cols=example_regression_columns)\n",
    "    dict_b = {}\n",
    "    dict_b['df'] = example_prediction['df'].copy()\n",
    "    if 'bin' in dict_b['df']:\n",
    "        dict_b['df'].drop(\"bin\", axis=1, inplace=True)\n",
    "    assert dict_a[\"df\"].round(10).equals(dict_b[\"df\"].round(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION single_step_create_predict FOR valid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the function results to the test results\n",
    "def test_single_step_create_predict_valid_params():\n",
    "    dict_a = single_step(training_csv=example_training_csv(), predict_csv=example_prediction_csv(), output_column=example_out_col,\n",
    "                         columns_not_required=example_not_required)\n",
    "    dict_a['df'].index = example_prediction['df'].index\n",
    "\n",
    "    b, c = dict_a[\"df\"].iloc[0].copy(), dict_a[\"df\"].iloc[1].copy()\n",
    "    dict_a[\"df\"].iloc[0], dict_a[\"df\"].iloc[1] = c, b\n",
    "    assert dict_a['df'].drop(\"bin\", axis=1).round(5).equals(\n",
    "        example_prediction['df'].copy().round(5)) and dict_a['fig'] == example_prediction_fig['fig']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION linear_reg_model_creation FOR misspelt columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide missplet column name for the out_col and then in the not_required list\n",
    "@pytest.mark.parametrize(\"a,b,c\", [\n",
    "    (example_dataframe, \"%_Sica_Contrate\", example_not_required),\n",
    "    (example_dataframe, example_out_col,\n",
    "     \"%_FE_Concentrate,Or_Pul_pH,Flotation_Column_01_Air_Fldeow,Flotation_Column_02_Airs_Flow,Flotafertion_Column_03_Air_Flow\")])\n",
    "def test_create_model_missplet_cols(a, b, c):\n",
    "    '''Testing the correct error dictionary is returned when no parameters are specified'''\n",
    "    assert model_creation_func(\n",
    "        df=a, output_column=b, columns_not_required=c) == example_false_model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION prediction_using_model FOR misspelt columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide some misspelt column names for the regression cols input\n",
    "def test_predict_missplet_cols():\n",
    "    '''Testing the correct error dictionary is returned when no parameters are specified'''\n",
    "    test_regression_cols_spell = \"%_Irn_Feed,%_Sla_Feed,Starch_Flow,Amina_Flow,Ore_Pulp_Flow,Ore_Pulp_Density,Flotation_Column_04_Air_Flow,Flotation_Column_05_Air_Flow,Flotation_Column_06_Air_Flow,Flotation_Column_07_Air_Flow,Flotation_Column_01_Level,Flotation_Column_02_Level,Flotation_Column_03_Level,Flotation_Column_04_Level,Flotation_Column_05_Level,Flotation_Column_06_Level,Flotation_Column_07_Level\".split(\n",
    "        \",\")\n",
    "    assert predict_func(model=example_true_model_output[\"reg\"],\n",
    "                        scaler_used=example_true_model_output[\"scaler_used\"], df=example_predict_dataframe,\n",
    "                        regression_cols=test_regression_cols_spell) == {\"df\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION linear_reg_model_creation FOR list variations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide different versions of list seperations by replacing the basic ',' with something else\n",
    "not_required_list = \"%_Iron_Concentrate,Ore_Pulp_pH,Flotation_Column_01_Air_Flow,Flotation_Column_02_Air_Flow,Flotation_Column_03_Air_Flow\"\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"a\", [' , ', ', ', ' ,'])\n",
    "def test_create_model_list_seperations(a):\n",
    "    '''Testing the correct error dictionary is returned when no parameters are specified'''\n",
    "    dict_a = model_creation_func(df=example_dataframe, output_column=example_out_col,\n",
    "                                 columns_not_required=not_required_list.replace(\",\", a))\n",
    "    dict_b = example_true_model_output\n",
    "    assert compare_model_dicts(dict_a, dict_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION prediction_using_model FOR list variations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide different versions of list seperations by replacing the basic ',' with something else\n",
    "@pytest.mark.parametrize(\"a\", [\" ,\", \" , \", \", \"])\n",
    "def test_predict_list_variations(a):\n",
    "    '''Testing the correct prediction results are returned when lists are seperated differently'''\n",
    "    prediction_output = predict_func(model=example_true_model_output[\"reg\"], scaler_used=example_true_model_output[\n",
    "                                     \"scaler_used\"], df=example_predict_dataframe, regression_cols=example_regression_columns.replace(\",\", a))\n",
    "    # print(example_prediction[\"df\"])\n",
    "    assert prediction_output[\"df\"].equals(example_prediction[\"df\"].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION linear_reg_model_creation FOR compare in_out_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the in_out_def input and output parameter names with the actual function parameters\n",
    "# and the output dictionary keys for both error and valid outputs\n",
    "def test_model_param_names():\n",
    "    var_a = [*in_out_def()[\"linear_reg_model_creation\"][\"inputs\"].keys()\n",
    "             ] == inspect.getargspec(model_creation_func)[0]\n",
    "    var_b = [*in_out_def()[\"linear_reg_model_creation\"][\"outputs\"].keys()] == [*model_creation_func(\n",
    "        df=example_dataframe, output_column=example_out_col, columns_not_required=example_not_required).keys()]\n",
    "    var_c = [*in_out_def()[\"linear_reg_model_creation\"]\n",
    "             [\"outputs\"].keys()] == [*model_creation_func().keys()]\n",
    "    assert var_a and var_b and var_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the in_out_def input and output parameter names with the actual function parameters\n",
    "# and the output dictionary keys for both error and valid outputs\n",
    "def test_predict_param_names():\n",
    "    var_a = [*in_out_def()[\"prediction_using_model\"][\"inputs\"].keys()\n",
    "             ] == inspect.getargspec(predict_func)[0]\n",
    "    var_b = [*in_out_def()[\"prediction_using_model\"][\"outputs\"].keys()] == [*predict_func(model=example_true_model_output[\"reg\"],\n",
    "                                                                                          scaler_used=example_true_model_output[\"scaler_used\"], df=example_predict_dataframe, regression_cols=example_regression_columns)]\n",
    "    var_c = [*in_out_def()[\"prediction_using_model\"][\"outputs\"].keys()\n",
    "             ] == [*predict_func().keys()]\n",
    "    assert var_a and var_b and var_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the in_out_def input and output parameter names with the actual function parameters\n",
    "# and the output dictionary keys for both error and valid outputs\n",
    "def test_single_step_create_predict_param_names():\n",
    "    var_a = [*in_out_def()[\"single_step_create_predict\"][\"inputs\"].keys()\n",
    "             ] == inspect.getargspec(single_step)[0]\n",
    "    var_b = [*in_out_def()[\"single_step_create_predict\"][\"outputs\"].keys()] == [*single_step(training_csv=example_training_csv(), predict_csv=example_prediction_csv(),\n",
    "                                                                                             output_column=example_out_col, columns_not_required=example_not_required)]\n",
    "    var_c = [*in_out_def()[\"single_step_create_predict\"]\n",
    "             [\"outputs\"].keys()] == [*single_step().keys()]\n",
    "    assert var_a and var_b and var_c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
